# -*- coding: utf-8 -*-
"""Copy of dynamic.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Yyx9QyDpdHrLr_CqU_gg3kScXvLsAZT9
"""


import numpy as np
import pandas as pd
import yfinance as yf
import matplotlib.pyplot as plt
from scipy.optimize import minimize
from scipy.stats import norm, skew, kurtosis
from scipy.stats.mstats import gmean
import os
import datetime
import sys

# ---------------------------------------------------------------------------
# 1. CREATE TIMESTAMPED OUTPUT FOLDER & SETUP LOGGING
# ---------------------------------------------------------------------------
name = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
output_folder = os.path.join(os.getcwd(), name)
os.makedirs(output_folder, exist_ok=True)

original_stdout = sys.stdout
log_path = os.path.join(output_folder, "results.txt")

try:
    sys.stdout = open(log_path, "w")

    # -----------------------------------------------------------------------
    # 2. DEFINE STUDY & INVESTMENT PERIODS
    # -----------------------------------------------------------------------
    study_start_date = '2019-01-01'
    study_end_date   = '2020-09-01'  # "in-sample" or initial period (optional for comparison)

    # Dynamic rebalancing will occur in this "investment" or "out-of-sample" period:
    invest_start_date = '2020-01-01'
    invest_end_date   = '2021-01-01'

    print("Study Period  :", study_start_date, " to ", study_end_date)
    print("Investment Period:", invest_start_date, " to ", invest_end_date)

    # -----------------------------------------------------------------------
    # 3. USER PARAMETERS
    # -----------------------------------------------------------------------
    num_portfolios = 50000   # Monte Carlo for plotting the frontier
    np.random.seed(100)
    initial_investment = 10000

    # **Dynamic Rebalancing Parameters**
    lookback_years = 2       # How many years of history to use for optimization
    rebalance_freq = 'Q'     # 'M' => monthly rebalancing, 'Q' => quarterly, etc.

    # -----------------------------------------------------------------------
    # 4. SYMBOLS (TICKERS) TO DOWNLOAD
    # -----------------------------------------------------------------------
    symbols = [
        "AAPL",  # Apple Inc. (Technology)
        # "TSLA",  # Tesla Inc. (Automotive)
        # "JPM",   # JPMorgan Chase & Co. (Banking)
        # "WMT",   # Walmart Inc. (Retail)
        # "JNJ",   # Johnson & Johnson (Pharmaceuticals)
        # "PEP",   # PepsiCo Inc. (Beverages)
        # "DIS",   # The Walt Disney Company (Entertainment)
        # "LMT",   # Lockheed Martin Corporation (Defense)
        "T",      # AT&T Inc. (Telecommunications)
        "GC=F",  # Gold Futures (Commodity)
        "CL=F",  # Crude Oil Futures (Commodity)
    ]
    benchmark = '^GSPC'  # S&P 500
    print("Symbols:", symbols)

    # -----------------------------------------------------------------------
    # 5. DOWNLOAD DATA FOR THE WHOLE SPAN (STUDY + INVESTMENT PERIOD)
    # -----------------------------------------------------------------------
    full_data = yf.download(symbols, start=study_start_date, end=invest_end_date)['Close']
    full_returns = full_data.dropna().pct_change().dropna()
    print("Data shape:", full_data.shape)
    print("Data downloaded. Now defining objective functions...")
    
    # -----------------------------------------------------------------------
    # 6. RELATIVE POWER SHARPE FUNCTION
    # -----------------------------------------------------------------------
    def compute_standard_sharpe(weights, returns, trading_days_per_year=252):
        returns = returns.dot(weights)
        returns = returns.squeeze()
        if returns.empty or returns.std() == 0:
            return np.nan
        return (returns.mean() / returns.std()) * np.sqrt(trading_days_per_year)


    def compute_relative_power_sharpe(weights, returns):
        returns = returns.dot(weights)
        returns = returns.squeeze()
        if returns.empty:
            return np.nan
        target_value = np.log(4)
        annual_factor = np.sqrt(252)
        def objective(P_X):
            expectation = np.mean(np.log(1 + (returns / P_X) ** 2))
            return (expectation - target_value) ** 2
        initial_guess = 1.0
        result = minimize(objective, initial_guess, bounds=[(0, None)])
        if result.success and not np.isnan(result.x[0]):
            P_X = float(result.x[0])
            return (np.mean(np.log(1+returns)) / P_X) * annual_factor if P_X > 0 else np.nan
        else:
            return np.nan


    def compute_snr_sharpe(weights, returns, trading_days_per_year=252):
        returns = returns.dot(weights)
        returns = returns.squeeze()
        if returns.empty:
            return np.nan
        log_returns = np.log(1 + returns)
        mean_lr = log_returns.mean()
        std_error = log_returns.std() / np.sqrt(len(log_returns))
        return (mean_lr / std_error) * np.sqrt(trading_days_per_year) if std_error > 0 else np.nan


    def compute_median_sharpe(weights, returns, trading_days_per_year=252):
        returns = returns.dot(weights)
        returns = returns.squeeze()
        if returns.empty:
            return np.nan
        med = np.median(returns)
        mad = np.median(np.abs(returns - med))
        return (med / mad) * np.sqrt(trading_days_per_year) if mad > 0 else np.nan


    def compute_sortino_ratio(weights, returns, trading_days_per_year=252):
        returns = returns.dot(weights)
        returns = returns.squeeze()
        if returns.empty:
            return np.nan
        mean_ret = returns.mean()
        neg_returns = returns[returns < 0]
        downside_std = neg_returns.std()
        return (mean_ret / downside_std) * np.sqrt(trading_days_per_year) if downside_std > 0 else np.nan


    def compute_max_drawdown(weights, returns):
        returns = returns.dot(weights)
        returns = returns.squeeze()
        if returns.empty:
            return np.nan
        cum_returns = (1 + returns).cumprod()
        peak = cum_returns.cummax()
        dd = (cum_returns - peak) / peak
        return dd.min()


    def compute_information_ratio(weights, returns, trading_days_per_year=252):
        returns = returns.dot(weights)
        returns = returns.squeeze()
        benchmark_returns = yf.download(benchmark, start=study_start_date, end=invest_end_date)['Close']
        benchmark_returns = benchmark_returns.squeeze()
        if returns.empty or benchmark_returns.empty:
            return np.nan
        aligned = pd.concat([returns, benchmark_returns], axis=1).dropna()
        if aligned.empty:
            return np.nan
        ex_ret = aligned.iloc[:, 0] - aligned.iloc[:, 1]
        if ex_ret.std() == 0:
            return np.nan
        return (ex_ret.mean() / ex_ret.std()) * np.sqrt(trading_days_per_year)


    def compute_mvar(weights, returns, confidence_level=0.95):
        returns = returns.dot(weights)
        returns = returns.squeeze()
        if returns.empty:
            return np.nan
        mean_ret = returns.mean()
        std_dev = returns.std()
        skewness = skew(returns)
        excess_kurt = kurtosis(returns, fisher=True)
        z = norm.ppf(confidence_level)
        mvar = (mean_ret + z * std_dev +
                ((z**2 - 1) / 6) * skewness * std_dev +
                ((z**3 - 3*z) / 24) * excess_kurt * std_dev)
        return float(mvar)


    def compute_ulcer_index(weights, returns):
        returns = returns.dot(weights)
        returns = returns.squeeze()
        if returns.empty:
            return np.nan
        cum_returns = (1 + returns).cumprod()
        peak = cum_returns.cummax()
        dd = (cum_returns - peak) / peak
        return np.sqrt(np.mean(dd**2))
    
    def compute_evar(weights, returns, alpha=0.95):
        returns = returns.dot(weights)
        returns = returns.squeeze()
        if returns.empty:
            return np.nan
        z_vals = np.linspace(0.01, 10, 100)
        mgf = lambda t: np.mean(np.exp(t * returns))
        evar_vals = [(1/t)*(np.log(mgf(t)) - np.log(alpha)) for t in z_vals if mgf(t) > 0]
        return min(evar_vals) if evar_vals else np.nan

    def compute_rlvar(weights, returns, alpha=0.95, kappa=0.5):
        returns = returns.dot(weights)
        returns = returns.squeeze()
        if returns.empty:
            return np.nan
        mgf_kappa = lambda t: np.mean((1 + t * returns / kappa) ** kappa)
        z_vals = np.linspace(0.01, 10, 100)
        rlvar_vals = [(1/t)*(np.log(mgf_kappa(t)) - np.log(alpha)) for t in z_vals if mgf_kappa(t) > 0]
        return min(rlvar_vals) if rlvar_vals else np.nan


    # -----------------------------------------------------------------------
    # 8. CONSTRAINTS, BOUNDS, INITIAL GUESS
    # -----------------------------------------------------------------------
    cons = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})
    bounds = tuple((0, 1) for _ in range(len(symbols)))
    init_guess = np.array([1 / len(symbols)] * len(symbols))

    # -----------------------------------------------------------------------
    # 9. DETAILED STATS FUNCTION
    # -----------------------------------------------------------------------
    def max_drawdown(return_series):
        comp_ret = (1 + return_series).cumprod()
        peak     = comp_ret.expanding(min_periods=1).max()
        dd       = (comp_ret / peak) - 1
        return dd.min()

    def portfolio_statistics(daily_port_ret):
        if len(daily_port_ret) == 0:
            return {}
        mean_return_annualized = gmean(1 + daily_port_ret) ** 252 - 1
        std_dev_annualized     = daily_port_ret.std() * np.sqrt(252)
        skw                    = skew(daily_port_ret)
        krt                    = kurtosis(daily_port_ret)
        mdd                    = max_drawdown(daily_port_ret)
        sharpe_ratio_val = (mean_return_annualized) / (std_dev_annualized + 1e-12)
        conf_level = 0.05
        cvar_val   = mean_return_annualized - std_dev_annualized * norm.ppf(conf_level)

        port_daily_annual = daily_port_ret * 252
        downside = port_daily_annual[port_daily_annual < 0]
        if len(downside) > 0:
            downside_std = downside.std()
            sortino = (port_daily_annual.mean()) / (downside_std + 1e-12)
        else:
            sortino = np.inf
        var_val = std_dev_annualized ** 2

        return {
            'Annualized Return': mean_return_annualized,
            'Annualized Volatility': std_dev_annualized,
            'Skewness': skw,
            'Kurtosis': krt,
            'Max Drawdown': mdd,
            'Sharpe Ratio': sharpe_ratio_val,
            'CVaR Approx': cvar_val,
            'Sortino Ratio': sortino,
            'Variance': var_val
        }
    def callback_function(x, *args,):	
        print(f"Iteration: {args[0].niter}\n"
              f"Fun value: {args[0].fun}\n"
              f"Barrier Parameter: {args[0].barrier_parameter}\n"
              f"Barrier Tolerance: {args[0].barrier_tolerance}\n"
              "================================================")
    # -----------------------------------------------------------------------
    # 10. EPOCH-BASED REBALANCING
    # -----------------------------------------------------------------------
    def dynamic_investment(
        full_rets,
        symbols_list,
        start_date,
        end_date,
        lookback_yrs,
        freq,
        obj_func,
        init_capital
    ):
        dates_idx = pd.date_range(start=start_date, end=end_date, freq=freq)
        if dates_idx[-1] < pd.to_datetime(end_date):
            dates_idx = dates_idx.append(pd.DatetimeIndex([pd.to_datetime(end_date)]))

        all_dates = []
        all_values = []
        capital = init_capital
        current_weights = None

        for i in range(1, len(dates_idx)):
            rebal_date = dates_idx[i]
            prev_date  = dates_idx[i - 1]
            lookback_start = rebal_date - pd.DateOffset(years=lookback_yrs)
            window_data = full_rets.loc[lookback_start : rebal_date - pd.Timedelta(days=1)]
            if len(window_data) == 0:
                continue

        if obj_func.__name__ == "compute_relative_power_sharpe":
            options = {'maxiter': 100000, 'disp': True, 'gtol': 1e-30, 'xtol': 1e-30, 'barrier_tol': 1e-30}
            result =  minimize(
                fun= lambda w: compute_relative_power_sharpe(w, full_rets),
                x0=init_guess,
                method='trust-constr',
                bounds=bounds,
                constraints=cons,
                tol=1e-30,
                options=options,
                callback=callback_function
            )
        else:
            result = minimize(
                lambda w: obj_func(w, full_rets),
                init_guess,
                method='SLSQP',
                bounds=bounds,
                constraints=cons
            )
            print("Optimization Concluded, line 262 dynamic")
            new_weights = result.x if result.success else init_guess

            # First period => adopt weights immediately
            if current_weights is None:
                current_weights = new_weights

            daily_range = full_rets.loc[prev_date : rebal_date - pd.Timedelta(days=1)]
            if len(daily_range) > 0:
                port_ret_series = daily_range.dot(current_weights)
                growth = (1 + port_ret_series).cumprod()
                sub_port_values = capital * growth

                for dt, val in sub_port_values.items():
                    all_dates.append(dt)
                    all_values.append(val)

                capital = sub_port_values.iloc[-1]
            current_weights = new_weights

        out_series = pd.Series(data=all_values, index=all_dates).sort_index()
        return out_series

    # -----------------------------------------------------------------------
    # 11. RUN DYNAMIC REBALANCING FOR EACH OBJECTIVE
    # -----------------------------------------------------------------------
    objectives = {
        'Standard Sharpe': compute_standard_sharpe,
        'Relative Power Sharpe': compute_relative_power_sharpe,
        'Signal-to-Noise Sharpe': compute_snr_sharpe,
        'Median Sharpe': compute_median_sharpe,
        'Sortino Ratio': compute_sortino_ratio,
        'Max Drawdown': compute_max_drawdown,
        'Information Ratio': compute_information_ratio,
        'Modified VaR (MVaR)': compute_mvar,
        'Entropic VaR (EVaR)': compute_evar,
        'Robust Log VaR (RLVaR)': compute_rlvar,
        'Ulcer Index': compute_ulcer_index
    }

    dynamic_results = {}
    for name, obj_func in objectives.items():
        print(f"\n=== Dynamic rebalancing for: {name} ===")
        dyn_series = dynamic_investment(
            full_rets   = full_returns,
            symbols_list= symbols,
            start_date  = invest_start_date,
            end_date    = invest_end_date,
            lookback_yrs= lookback_years,
            freq        = rebalance_freq,
            obj_func    = obj_func,
            init_capital= initial_investment
        )
        dynamic_results[name] = dyn_series

        if len(dyn_series) == 0:
            print("No rebalancing data produced (check date ranges).")
        else:
            final_val = dyn_series.iloc[-1]
            print(f"Final Portfolio Value   : ${final_val:,.2f}")
            daily_returns_series = dyn_series.dropna().pct_change().dropna()
            stats = portfolio_statistics(daily_returns_series)

            print("Key Stats:")
            for k, v in stats.items():
                if k in ['Annualized Return','Annualized Volatility','CVaR Approx','Max Drawdown']:
                    print(f"  {k}: {v*100:.2f}%")
                else:
                    print(f"  {k}: {v:.4f}")

    # -----------------------------------------------------------------------
    # 12. (OPTIONAL) PLOT DYNAMIC RESULTS
    # -----------------------------------------------------------------------
    plt.figure(figsize=(12, 8))
    for name, series_vals in dynamic_results.items():
        if len(series_vals) > 0:
            plt.plot(series_vals.index, series_vals, label=f"Dynamic {name}")

    plt.title("Dynamic (Epoch-Based) Portfolio Value Over Time")
    plt.xlabel("Date")
    plt.ylabel("Portfolio Value ($)")
    plt.legend()
    plt.grid(True)
    plt.savefig(os.path.join(output_folder, "dynamic_rebalancing.png"), dpi=600)
    plt.close()

    # -----------------------------------------------------------------------
    # 13. (OPTIONAL) STATIC EFFICIENT FRONTIER (STUDY PERIOD)
    # -----------------------------------------------------------------------
    static_data = full_data.loc[study_start_date:study_end_date].dropna().pct_change().dropna()

    port_returns = []
    port_volatility = []
    sharpe_ratios = []
    num_assets = len(symbols)

    for _ in range(num_portfolios):
        w = np.random.random(num_assets)
        w /= w.sum()
        r_annual = np.dot(w, static_data.mean()) * 252
        v_annual = np.sqrt(np.dot(w.T, np.dot(static_data.cov() * 252, w)))
        sr = r_annual / (v_annual + 1e-12)
        port_returns.append(r_annual)
        port_volatility.append(v_annual)
        sharpe_ratios.append(sr)

    plt.figure(figsize=(12, 8))
    scatter = plt.scatter(port_volatility, port_returns, c=sharpe_ratios,
                          cmap='viridis', alpha=0.5)
    plt.colorbar(scatter, label='Sharpe Ratio')
    plt.xlabel('Volatility')
    plt.ylabel('Return')
    plt.title('Static Efficient Frontier (Study Period)')
    plt.savefig(os.path.join(output_folder, "static_frontier.png"), dpi=600)
    plt.close()

    # -----------------------------------------------------------------------
    # 14. COMPARE DYNAMIC vs. STATIC ALLOCATIONS IN ONE CHART
    # -----------------------------------------------------------------------
    # For each objective, we'll:
    #   1) Optimize using the entire study period to get "static_weights."
    #   2) Apply those static weights out-of-sample, generating a "static_series."
    #   3) Plot both the dynamic_series and static_series together in one plot.

    # 14a) Compute static results for each objective
    static_results = {}
    for name, obj_func in objectives.items():
        # Optimize using study period
        if obj_func.__name__ == "compute_relative_power_sharpe":
            options = {'maxiter': 100000, 'disp': True, 'gtol': 1e-30, 'xtol': 1e-30, 'barrier_tol': 1e-30}
            static_opt_result =  minimize(
                fun=lambda w: compute_relative_power_sharpe(w, static_data),
                x0=init_guess,
                method='trust-constr',
                bounds=bounds,
                constraints=cons,
                tol=1e-30,
                options=options,
                callback=callback_function
            )
        else:
            static_opt_result = minimize(
                lambda w: obj_func(w, static_data),
                init_guess,
                method='SLSQP',
                bounds=bounds,
                constraints=cons
            )
            print("Optimization Concluded, line 404 static")


        if not static_opt_result.success:
            static_weights = init_guess
        else:
            static_weights = static_opt_result.x

        # Apply these static weights out-of-sample
        out_data = full_returns.loc[invest_start_date: invest_end_date]
        if len(out_data) == 0:
            static_series = pd.Series(dtype=float)
        else:
            port_ret_series = out_data.dot(static_weights)
            growth = (1 + port_ret_series).cumprod()
            static_series = initial_investment * growth

        static_results[name] = static_series

    # 14b) Plot all in one figure (warning: can be busy with many lines!)
    plt.figure(figsize=(12, 8))
    for name in objectives.keys():
        # Dynamic
        dyn_series = dynamic_results[name]
        if len(dyn_series) > 0:
            plt.plot(dyn_series.index, dyn_series, label=f"Dynamic {name}")

        # Static
        stc_series = static_results[name]
        if len(stc_series) > 0:
            plt.plot(stc_series.index, stc_series, '--', label=f"Static {name}")

    plt.title("Dynamic vs. Static Allocations (Same Out-of-Sample Period)")
    plt.xlabel("Date")
    plt.ylabel("Portfolio Value ($)")
    plt.legend()
    plt.grid(True)
    plt.savefig(os.path.join(output_folder, "dynamic_vs_static.png"), dpi=600)
    plt.close()

finally:
    # Safely restore stdout
    sys.stdout.close()
    sys.stdout = original_stdout

print(f"All results and plots have been saved to: {output_folder}")