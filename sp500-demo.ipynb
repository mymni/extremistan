{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kp63WoDshcvk",
        "outputId": "22e9a9fb-505c-4a81-cafc-83f926a7eb34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing portfolio_module.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile portfolio_module.py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import minimize\n",
        "from scipy.stats import norm, skew, kurtosis\n",
        "from scipy.stats.mstats import gmean\n",
        "import datetime\n",
        "\n",
        "def compute_relative_power_sharpe(returns_series):\n",
        "    if returns_series.empty:\n",
        "        return np.nan\n",
        "    target_value = np.log(4)\n",
        "    def objective(P_X):\n",
        "        return (np.mean(np.log(1 + (returns_series / P_X)**2)) - target_value)**2\n",
        "    initial_guess = 1.0\n",
        "    result = minimize(objective, initial_guess, bounds=[(1e-9, None)])\n",
        "    if result.success and not np.isnan(result.x[0]):\n",
        "        P_X = float(result.x[0])\n",
        "        mean_return = returns_series.mean()\n",
        "        return (mean_return / P_X) if P_X > 0 else np.nan\n",
        "    else:\n",
        "        return np.nan\n",
        "\n",
        "def objective_sharpe(weights, daily_ret):\n",
        "    portfolio_return = np.dot(weights, daily_ret.mean()) * 252\n",
        "    portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(daily_ret.cov() * 252, weights)))\n",
        "    return -(portfolio_return / (portfolio_volatility + 1e-12))\n",
        "\n",
        "def objective_cvar(weights, daily_ret):\n",
        "    port_ret = np.dot(daily_ret, weights)\n",
        "    mean_annual = port_ret.mean() * 252\n",
        "    std_annual  = port_ret.std()  * np.sqrt(252)\n",
        "    conf_level = 0.05\n",
        "    cvar_metric = mean_annual - std_annual * norm.ppf(conf_level)\n",
        "    return -cvar_metric\n",
        "\n",
        "def objective_sortino(weights, daily_ret):\n",
        "    port_daily_annualized = np.dot(daily_ret, weights) * 252\n",
        "    downside = port_daily_annualized[port_daily_annualized < 0]\n",
        "    if len(downside) == 0:\n",
        "        return -1e9\n",
        "    downside_std = downside.std()\n",
        "    sortino_ratio = port_daily_annualized.mean() / (downside_std + 1e-12)\n",
        "    return -sortino_ratio\n",
        "\n",
        "def objective_variance(weights, daily_ret):\n",
        "    cov = daily_ret.cov() * 252\n",
        "    return np.dot(weights.T, np.dot(cov, weights))\n",
        "\n",
        "def objective_relative_power_sharpe(weights, daily_ret):\n",
        "    port_returns = pd.Series(np.dot(daily_ret, weights), index=daily_ret.index)\n",
        "    rps = compute_relative_power_sharpe(port_returns)\n",
        "    return -rps\n",
        "\n",
        "def dynamic_investment(full_rets, study_start_date, study_end_date, invest_start_date, invest_end_date,\n",
        "                       lookback_years, freq, obj_func, init_capital, symbols):\n",
        "    # Set up initial guess, bounds, and constraints based on number of assets\n",
        "    n = len(symbols)\n",
        "    cons = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
        "    bounds = tuple((-1, 1) for _ in range(n))\n",
        "    init_guess = np.array([1.0 / n] * n)\n",
        "\n",
        "    # Create a date index for the investment period\n",
        "    dates_idx = pd.date_range(start=invest_start_date, end=invest_end_date, freq=freq)\n",
        "    if dates_idx[-1] < pd.to_datetime(invest_end_date):\n",
        "        dates_idx = dates_idx.append(pd.DatetimeIndex([pd.to_datetime(invest_end_date)]))\n",
        "    all_dates = []\n",
        "    all_values = []\n",
        "    capital = init_capital\n",
        "    current_weights = None\n",
        "\n",
        "    for i in range(1, len(dates_idx)):\n",
        "        rebal_date = dates_idx[i]\n",
        "        prev_date = dates_idx[i - 1]\n",
        "        # Ensure the lookback period does not start before the study period begins:\n",
        "        lookback_start = max(pd.to_datetime(study_start_date), rebal_date - pd.DateOffset(years=lookback_years))\n",
        "        window_data = full_rets.loc[lookback_start: rebal_date - pd.Timedelta(days=1)]\n",
        "        if len(window_data) == 0:\n",
        "            continue\n",
        "        result = minimize(lambda w: obj_func(w, window_data),\n",
        "                          init_guess, method='SLSQP',\n",
        "                          bounds=bounds, constraints=cons)\n",
        "        new_weights = result.x if result.success else init_guess\n",
        "\n",
        "        if current_weights is None:\n",
        "            current_weights = new_weights\n",
        "\n",
        "        daily_range = full_rets.loc[prev_date: rebal_date - pd.Timedelta(days=1)]\n",
        "        if len(daily_range) > 0:\n",
        "            port_ret_series = daily_range.dot(current_weights)\n",
        "            growth = (1 + port_ret_series).cumprod()\n",
        "            sub_port_values = capital * growth\n",
        "            for dt, val in sub_port_values.items():\n",
        "                all_dates.append(dt)\n",
        "                all_values.append(val)\n",
        "            capital = sub_port_values.iloc[-1]\n",
        "        current_weights = new_weights\n",
        "\n",
        "    out_series = pd.Series(data=all_values, index=all_dates).sort_index()\n",
        "    return out_series\n",
        "\n",
        "def run_simulation(study_start_date, study_end_date, invest_start_date, invest_end_date,\n",
        "                   symbols, objective_choice='Sharpe', initial_investment=10000,\n",
        "                   lookback_years=2, rebalance_freq='Q'):\n",
        "    # Download full data from study_start_date to invest_end_date.\n",
        "    full_data = yf.download(symbols, start=study_start_date, end=invest_end_date)['Close']\n",
        "    full_returns = full_data.pct_change().dropna()\n",
        "\n",
        "    # Set up available objective functions.\n",
        "    objectives = {\n",
        "        'Sharpe': objective_sharpe,\n",
        "        'CVaR': objective_cvar,\n",
        "        'Sortino': objective_sortino,\n",
        "        'Variance': objective_variance,\n",
        "        'PowerSharpe': objective_relative_power_sharpe\n",
        "    }\n",
        "    if objective_choice not in objectives:\n",
        "        selected_objective = objective_sharpe\n",
        "    else:\n",
        "        selected_objective = objectives[objective_choice]\n",
        "\n",
        "    # Run the dynamic investment simulation.\n",
        "    result_series = dynamic_investment(full_returns, study_start_date, study_end_date,\n",
        "                                       invest_start_date, invest_end_date, lookback_years,\n",
        "                                       rebalance_freq, selected_objective, initial_investment, symbols)\n",
        "    final_value = result_series.iloc[-1] if len(result_series) > 0 else None\n",
        "\n",
        "    # Create a plot.\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    if len(result_series) > 0:\n",
        "        ax.plot(result_series.index, result_series, label=f\"Dynamic {objective_choice}\")\n",
        "    else:\n",
        "        ax.text(0.5, 0.5, \"No rebalancing data produced.\", horizontalalignment='center',\n",
        "                verticalalignment='center', transform=ax.transAxes)\n",
        "    ax.set_title(\"Dynamic Portfolio Value Over Time\")\n",
        "    ax.set_xlabel(\"Date\")\n",
        "    ax.set_ylabel(\"Portfolio Value ($)\")\n",
        "    ax.legend()\n",
        "    ax.grid(True)\n",
        "\n",
        "    return final_value, fig"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ranking_module.py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import seaborn as sns\n",
        "from scipy.stats import norm, t, skewnorm, gennorm, entropy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -----------------------------\n",
        "# Risk Measure Functions\n",
        "# -----------------------------\n",
        "def compute_standard_sharpe(returns, trading_days_per_year=252):\n",
        "    returns = returns.squeeze()\n",
        "    if returns.empty or returns.std() == 0:\n",
        "        return np.nan\n",
        "    return (returns.mean() / returns.std()) * np.sqrt(trading_days_per_year)\n",
        "\n",
        "def compute_relative_power_sharpe(returns):\n",
        "    returns = returns.squeeze()\n",
        "    if returns.empty:\n",
        "        return np.nan\n",
        "    target_value = np.log(4)\n",
        "    annual_factor = np.sqrt(252)\n",
        "    def objective(P_X):\n",
        "        return (np.mean(np.log(1 + (returns / P_X) ** 2)) - target_value) ** 2\n",
        "    from scipy.optimize import minimize\n",
        "    result = minimize(objective, 1.0, bounds=[(0, None)])\n",
        "    if result.success and not np.isnan(result.x[0]):\n",
        "        P_X = float(result.x[0])\n",
        "        return (np.mean(np.log(1 + returns)) / P_X) * annual_factor if P_X > 0 else np.nan\n",
        "    else:\n",
        "        return np.nan\n",
        "\n",
        "def compute_snr_sharpe(returns, trading_days_per_year=252):\n",
        "    returns = returns.squeeze()\n",
        "    if returns.empty:\n",
        "        return np.nan\n",
        "    log_returns = np.log(1 + returns)\n",
        "    mean_lr = log_returns.mean()\n",
        "    std_error = log_returns.std() / np.sqrt(len(log_returns))\n",
        "    if std_error == 0:\n",
        "        return np.nan\n",
        "    return (mean_lr / std_error) * np.sqrt(trading_days_per_year)\n",
        "\n",
        "def compute_median_sharpe(returns, trading_days_per_year=252):\n",
        "    returns = returns.squeeze()\n",
        "    if returns.empty:\n",
        "        return np.nan\n",
        "    med = np.median(returns)\n",
        "    mad = np.median(np.abs(returns - med))\n",
        "    if mad == 0:\n",
        "        return np.nan\n",
        "    return (med / mad) * np.sqrt(trading_days_per_year)\n",
        "\n",
        "def compute_sortino_ratio(returns, trading_days_per_year=252):\n",
        "    returns = returns.squeeze()\n",
        "    if returns.empty:\n",
        "        return np.nan\n",
        "    mean_ret = returns.mean()\n",
        "    neg_returns = returns[returns < 0]\n",
        "    if neg_returns.std() == 0:\n",
        "        return np.nan\n",
        "    return (mean_ret / neg_returns.std()) * np.sqrt(trading_days_per_year)\n",
        "\n",
        "def compute_max_drawdown(returns):\n",
        "    returns = returns.squeeze()\n",
        "    if returns.empty:\n",
        "        return np.nan\n",
        "    cum_returns = (1 + returns).cumprod()\n",
        "    peak = cum_returns.cummax()\n",
        "    dd = (cum_returns - peak) / peak\n",
        "    return dd.min()\n",
        "\n",
        "def compute_information_ratio(returns, benchmark_returns, trading_days_per_year=252):\n",
        "    returns = returns.squeeze()\n",
        "    benchmark_returns = benchmark_returns.squeeze()\n",
        "    aligned = pd.concat([returns, benchmark_returns], axis=1).dropna()\n",
        "    if aligned.empty:\n",
        "        return np.nan\n",
        "    ex_ret = aligned.iloc[:, 0] - aligned.iloc[:, 1]\n",
        "    if ex_ret.std() == 0:\n",
        "        return np.nan\n",
        "    return (ex_ret.mean() / ex_ret.std()) * np.sqrt(trading_days_per_year)\n",
        "\n",
        "def compute_mvar(returns, confidence_level=0.95):\n",
        "    returns = returns.squeeze()\n",
        "    if returns.empty:\n",
        "        return np.nan\n",
        "    mean_ret = returns.mean()\n",
        "    std_dev = returns.std()\n",
        "    z = norm.ppf(confidence_level)\n",
        "    return mean_ret + z * std_dev\n",
        "\n",
        "def compute_evar(returns, alpha=0.95):\n",
        "    returns = returns.squeeze()\n",
        "    if returns.empty:\n",
        "        return np.nan\n",
        "    z_vals = np.linspace(0.01, 10, 100)\n",
        "    mgf = lambda t: np.mean(np.exp(t * returns))\n",
        "    evar_vals = [(1 / t) * (np.log(mgf(t)) - np.log(alpha)) for t in z_vals if mgf(t) > 0]\n",
        "    return min(evar_vals) if evar_vals else np.nan\n",
        "\n",
        "def compute_rlvar(returns, alpha=0.95, kappa=0.5):\n",
        "    returns = returns.squeeze()\n",
        "    if returns.empty:\n",
        "        return np.nan\n",
        "    mgf_kappa = lambda t: np.mean((1 + t * returns / kappa) ** kappa)\n",
        "    z_vals = np.linspace(0.01, 10, 100)\n",
        "    rlvar_vals = [(1 / t) * (np.log(mgf_kappa(t)) - np.log(alpha)) for t in z_vals if mgf_kappa(t) > 0]\n",
        "    return min(rlvar_vals) if rlvar_vals else np.nan\n",
        "\n",
        "def compute_ulcer_index(returns):\n",
        "    returns = returns.squeeze()\n",
        "    if returns.empty:\n",
        "        return np.nan\n",
        "    cum_returns = (1 + returns).cumprod()\n",
        "    peak = cum_returns.cummax()\n",
        "    dd = (cum_returns - peak) / peak\n",
        "    return np.sqrt(np.mean(dd ** 2))\n",
        "\n",
        "# -----------------------------\n",
        "# Main Function: ranking_plot\n",
        "# -----------------------------\n",
        "def ranking_plot(symbols, static_start, static_end, benchmark_symbol):\n",
        "    \"\"\"\n",
        "    For a given list of stock symbols and a benchmark,\n",
        "    fetches historical data between static_start and static_end,\n",
        "    computes risk metrics for each stock, computes unified integer risk rankings,\n",
        "    creates a heatmap figure (without the color bar), and returns that figure.\n",
        "\n",
        "    Parameters:\n",
        "      - symbols (list): List of stock tickers.\n",
        "      - static_start (str): Start date ('YYYY-MM-DD').\n",
        "      - static_end (str): End date ('YYYY-MM-DD').\n",
        "      - benchmark_symbol (str): Benchmark ticker.\n",
        "\n",
        "    Returns:\n",
        "      - fig (matplotlib.figure.Figure): Heatmap figure of unified risk rankings.\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    import yfinance as yf\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "\n",
        "    # Fetch historical data and compute returns for each stock.\n",
        "    returns_data = {}\n",
        "    for symbol in symbols:\n",
        "        data = yf.download(symbol, start=static_start, end=static_end, progress=False)\n",
        "        if data.empty:\n",
        "            print(f\"No data for {symbol}\")\n",
        "            continue\n",
        "        price_series = data['Adj Close'] if 'Adj Close' in data.columns else data['Close']\n",
        "        returns = price_series.pct_change().dropna()\n",
        "        if returns.empty:\n",
        "            print(f\"No returns data for {symbol}\")\n",
        "            continue\n",
        "        returns_data[symbol] = returns\n",
        "\n",
        "    # Fetch benchmark data.\n",
        "    benchmark_data = yf.download(benchmark_symbol, start=static_start, end=static_end, progress=False)\n",
        "    if benchmark_data.empty:\n",
        "        raise ValueError(\"No benchmark data available.\")\n",
        "    benchmark_series = benchmark_data['Adj Close'] if 'Adj Close' in benchmark_data.columns else benchmark_data['Close']\n",
        "    benchmark_returns = benchmark_series.pct_change().dropna()\n",
        "\n",
        "    # Define risk measure functions.\n",
        "    risk_measures = {\n",
        "        'Standard Sharpe': lambda r: compute_standard_sharpe(r),\n",
        "        'Relative Power Sharpe': lambda r: compute_relative_power_sharpe(r),\n",
        "        'SNR Sharpe': lambda r: compute_snr_sharpe(r),\n",
        "        'Median Sharpe': lambda r: compute_median_sharpe(r),\n",
        "        'Sortino Ratio': lambda r: compute_sortino_ratio(r),\n",
        "        'Maximum Drawdown': lambda r: compute_max_drawdown(r),\n",
        "        'Information Ratio': lambda r: compute_information_ratio(r, benchmark_returns),\n",
        "        'MVaR': lambda r: compute_mvar(r),\n",
        "        'EVaR': lambda r: compute_evar(r),\n",
        "        'RLVaR': lambda r: compute_rlvar(r),\n",
        "        'Ulcer Index': lambda r: compute_ulcer_index(r)\n",
        "    }\n",
        "\n",
        "    # Compute metrics for each risk measure.\n",
        "    metrics_dict = {name: {} for name in risk_measures.keys()}\n",
        "    for symbol, returns in returns_data.items():\n",
        "        for name, func in risk_measures.items():\n",
        "            try:\n",
        "                metrics_dict[name][symbol] = func(returns)\n",
        "            except Exception:\n",
        "                metrics_dict[name][symbol] = np.nan\n",
        "\n",
        "    metrics_df = pd.DataFrame(metrics_dict)\n",
        "\n",
        "    # Invert metrics for which higher is better so that lower values imply lower risk.\n",
        "    metrics_higher_is_better = ['Standard Sharpe', 'Relative Power Sharpe', 'SNR Sharpe', 'Median Sharpe', 'Sortino Ratio', 'Information Ratio']\n",
        "    risk_scores = metrics_df.copy()\n",
        "    for metric in risk_scores.columns:\n",
        "        if metric in metrics_higher_is_better:\n",
        "            risk_scores[metric] = -risk_scores[metric]\n",
        "\n",
        "    unified_risk_ranking = risk_scores.rank(ascending=True, method='average')\n",
        "    # Convert to integer ranks.\n",
        "    unified_risk_ranking = unified_risk_ranking.round().astype(int)\n",
        "\n",
        "    # Create heatmap figure without the color bar.\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    sns.heatmap(unified_risk_ranking, annot=True, fmt=\"d\", cmap=\"coolwarm\", linewidths=0.5, ax=ax, cbar=False)\n",
        "    ax.set_title('Static Stock Rankings (1 = Least Risk)', fontsize=16)\n",
        "    ax.set_xlabel('Risk Metrics', fontsize=14)\n",
        "    ax.set_ylabel('Stocks', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmzLdtrJ2IBO",
        "outputId": "a08205a8-5c45-4a12-93c2-53384e6a2188"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ranking_module.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile rolling_basis_module.py\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "# import each of your measure-functions:\n",
        "from ranking_module import (\n",
        "    compute_standard_sharpe,\n",
        "    compute_sortino_ratio,\n",
        "    compute_median_sharpe,\n",
        "    compute_snr_sharpe,\n",
        "    compute_relative_power_sharpe,\n",
        "    compute_max_drawdown,\n",
        "    compute_information_ratio,\n",
        "    compute_mvar,\n",
        "    compute_evar,\n",
        "    compute_rlvar,\n",
        "    compute_ulcer_index,\n",
        ")\n",
        "\n",
        "# Map human-friendly names → functions\n",
        "RISK_FUNCS = {\n",
        "    'Standard Sharpe': compute_standard_sharpe,\n",
        "    'Sortino Ratio': compute_sortino_ratio,\n",
        "    'Median Sharpe': compute_median_sharpe,\n",
        "    'SNR Sharpe': compute_snr_sharpe,\n",
        "    'Power Sharpe': compute_relative_power_sharpe,\n",
        "    'Max Drawdown': compute_max_drawdown,\n",
        "    'Information Ratio': compute_information_ratio,\n",
        "    'MVaR': compute_mvar,\n",
        "    'EVaR': compute_evar,\n",
        "    'RLVaR': compute_rlvar,\n",
        "    'Ulcer Index': compute_ulcer_index,\n",
        "}\n",
        "\n",
        "def compute_rolling_risk(ticker, start_date, end_date, window=126,\n",
        "                         measures=None, benchmark=None):\n",
        "    \"\"\"\n",
        "    If measures is None, compute all in RISK_FUNCS.\n",
        "    If benchmark is needed by some measures (like info ratio), pass it here.\n",
        "    \"\"\"\n",
        "    df = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
        "    price = df.get('Adj Close', df['Close'])\n",
        "    daily_ret = price.pct_change().dropna()\n",
        "\n",
        "    dates = daily_ret.index[window-1:]\n",
        "    # decide which metrics to compute\n",
        "    measures = measures or list(RISK_FUNCS.keys())\n",
        "    risk_df = pd.DataFrame(index=dates, columns=measures, dtype=float)\n",
        "\n",
        "    # if info ratio needs a benchmark series pre-computed:\n",
        "    if 'Information Ratio' in measures and benchmark is not None:\n",
        "        benchmark_price = benchmark.get('Adj Close', benchmark['Close'])\n",
        "        benchmark_ret = benchmark_price.pct_change().dropna()\n",
        "    else:\n",
        "        benchmark_ret = None\n",
        "\n",
        "    for dt in dates:\n",
        "        window_ret = daily_ret.loc[:dt].tail(window)\n",
        "        for name in measures:\n",
        "            func = RISK_FUNCS[name]\n",
        "            if name == 'Information Ratio':\n",
        "                risk_df.at[dt, name] = func(window_ret, benchmark_ret)\n",
        "            else:\n",
        "                risk_df.at[dt, name] = func(window_ret)\n",
        "\n",
        "    # compute rankings if you want to return those too\n",
        "    rank_df = risk_df.rank(ascending=True, method='average')\n",
        "    return risk_df, rank_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8DZheQzKueO",
        "outputId": "a814d528-f015-4bd1-e852-94748aae601f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing rolling_basis_module.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import rolling_basis_module    as rbm\n",
        "import portfolio_module as pm\n",
        "import ranking_module as rm\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Define a common list of stock options.\n",
        "st.set_page_config(layout=\"wide\")\n",
        "\n",
        "st.title(\"Trading in Extremistan\")\n",
        "\n",
        "stock_options = [\"AAPL\",\"TSLA\",\"JPM\",\"WMT\",\"JNJ\",\"PEP\",\"DIS\",\"LMT\",\"T\",\"GOOGL\"]\n",
        "\n",
        "tabs = st.tabs([\n",
        "    \"Dynamic Portfolio Simulation\",\n",
        "    \"Static Stock Ranking\",\n",
        "    \"Distribution Fitting\",\n",
        "    \"Rolling-Basis Risk\"\n",
        "])\n",
        "\n",
        "# ---------------- Dynamic Simulation Tab ----------------\n",
        "with tabs[0]:\n",
        "    st.markdown(\"\"\"\n",
        "    ### Dynamic Portfolio Simulation\n",
        "    Use the controls below to set the training (study) and testing periods, and select up to 8 stock tickers.\n",
        "    \"\"\")\n",
        "    study_start = st.date_input(\"Study Start Date (Training)\", datetime(2009, 1, 1), key=\"dyn_start\")\n",
        "    study_end = st.date_input(\"Study End Date (Training) & Investment Start Date (Testing)\", datetime(2019, 12, 1), key=\"dyn_end\")\n",
        "    invest_end = st.date_input(\"Investment End Date (Testing)\", datetime(2020, 9, 1), key=\"dyn_invest_end\")\n",
        "\n",
        "    selected_tickers = st.multiselect(\"Select up to 8 Stock Tickers\", options=stock_options,\n",
        "                                      default=[\"AAPL\", \"TSLA\", \"JPM\", \"WMT\", \"JNJ\", \"PEP\", \"DIS\", \"LMT\"], key=\"dyn_tickers\")\n",
        "    if len(selected_tickers) > 8:\n",
        "        st.error(\"Please select at most 8 tickers.\")\n",
        "\n",
        "    objective_choice = st.selectbox(\"Select Objective Function\",\n",
        "                                    options=[\"Sharpe\", \"CVaR\", \"Sortino\", \"Variance\", \"PowerSharpe\"], key=\"dyn_obj\")\n",
        "\n",
        "    if st.button(\"Run Dynamic Simulation\", key=\"dyn_run\"):\n",
        "        if len(selected_tickers) > 8:\n",
        "            st.error(\"Too many tickers selected. Please choose 8 or fewer.\")\n",
        "        else:\n",
        "            study_start_date = study_start.strftime(\"%Y-%m-%d\")\n",
        "            study_end_date = study_end.strftime(\"%Y-%m-%d\")\n",
        "            invest_start_date = study_end_date  # As required.\n",
        "            invest_end_date = invest_end.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "            st.info(\"Running simulation. This may take a few moments...\")\n",
        "            final_value, fig = pm.run_simulation(\n",
        "                study_start_date, study_end_date,\n",
        "                invest_start_date, invest_end_date,\n",
        "                selected_tickers,\n",
        "                objective_choice=objective_choice,\n",
        "                initial_investment=10000,\n",
        "                lookback_years=2,\n",
        "                rebalance_freq='Q'\n",
        "            )\n",
        "            if final_value is not None:\n",
        "                st.success(f\"Final Portfolio Value: ${final_value:,.2f}\")\n",
        "            else:\n",
        "                st.error(\"Simulation did not produce any results. Check parameters and data availability.\")\n",
        "            st.pyplot(fig)\n",
        "\n",
        "# ---------------- Static Ranking Tab ----------------\n",
        "with tabs[1]:\n",
        "    st.markdown(\"\"\"\n",
        "    ### Static Stock Ranking\n",
        "    This demo computes unified risk rankings (displayed as a heatmap) across a full static period.\n",
        "    \"\"\")\n",
        "    static_start = st.date_input(\"Static Period Start Date\", datetime(2018, 1, 1), key=\"stat_start\")\n",
        "    static_end = st.date_input(\"Static Period End Date\", datetime(2021, 9, 30), key=\"stat_end\")\n",
        "    default_stocks = [\"NEM\", \"GOLD\", \"APA\"]\n",
        "    ranking_symbols = st.multiselect(\"Select Stocks for Ranking\",\n",
        "                                     options=[\"NEM\", \"GOLD\", \"APA\", \"TSLA\", \"AAPL\", \"JPM\"],\n",
        "                                     default=default_stocks, key=\"stat_symbols\")\n",
        "    # Benchmark is hardcoded to \"^GSPC\" and not shown.\n",
        "    benchmark_symbol = \"^GSPC\"\n",
        "\n",
        "    if st.button(\"Show Ranking Heatmap\", key=\"stat_run\"):\n",
        "        s_start = static_start.strftime(\"%Y-%m-%d\")\n",
        "        s_end = static_end.strftime(\"%Y-%m-%d\")\n",
        "        st.info(\"Fetching data and computing rankings. Please wait...\")\n",
        "        try:\n",
        "            fig = rm.ranking_plot(ranking_symbols, s_start, s_end, benchmark_symbol)\n",
        "            st.pyplot(fig)\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error computing ranking: {e}\")\n",
        "\n",
        "# ---------------- Distribution Fitting Tab ----------------\n",
        "with tabs[2]:\n",
        "    st.markdown(\"### Distribution Fitting (Gaussian vs Student-t)\")\n",
        "    fit_stock = st.selectbox(\"Select Stock for Fitting Analysis\", options=stock_options, key=\"fit_stock\")\n",
        "    fit_start = st.date_input(\"Fitting Analysis Start Date\", datetime(2020, 1, 1), key=\"fit_start\")\n",
        "    fit_end = st.date_input(\"Fitting Analysis End Date\", datetime(2020, 12, 31), key=\"fit_end\")\n",
        "\n",
        "    if st.button(\"Run Distribution Fitting\", key=\"fit_run\"):\n",
        "         fit_start_date = fit_start.strftime(\"%Y-%m-%d\")\n",
        "         fit_end_date = fit_end.strftime(\"%Y-%m-%d\")\n",
        "         data_fit = yf.download(fit_stock, start=fit_start_date, end=fit_end_date, progress=False)\n",
        "         if data_fit.empty:\n",
        "             st.error(\"No data fetched for the selected stock.\")\n",
        "         else:\n",
        "             price_series_fit = data_fit['Adj Close'] if 'Adj Close' in data_fit.columns else data_fit['Close']\n",
        "             returns_fit = price_series_fit.pct_change().dropna()\n",
        "             if returns_fit.empty:\n",
        "                 st.error(\"No returns data computed.\")\n",
        "             else:\n",
        "                 from scipy.stats import norm, t\n",
        "                 norm_params = norm.fit(returns_fit)\n",
        "                 t_params = t.fit(returns_fit)\n",
        "\n",
        "                 fig_fit, ax_fit = plt.subplots(figsize=(10, 6))\n",
        "                 ax_fit.hist(returns_fit, bins=50, density=True, alpha=0.6, color=\"gray\", label=\"Empirical\")\n",
        "                 x_fit = np.linspace(returns_fit.min(), returns_fit.max(), 1000)\n",
        "                 ax_fit.plot(x_fit, norm.pdf(x_fit, *norm_params), label=\"Gaussian Fit\", color=\"blue\", lw=2)\n",
        "                 ax_fit.plot(x_fit, t.pdf(x_fit, *t_params), label=\"Student-t Fit\", color=\"red\", lw=2)\n",
        "                 ax_fit.legend()\n",
        "                 ax_fit.set_title(f\"Distribution Fitting for {fit_stock}\")\n",
        "                 st.pyplot(fig_fit)\n",
        "\n",
        "# ----------- Rolling-Basis Risk & Ranking Evolution -----------\n",
        "with tabs[3]:\n",
        "    st.header(\"Rolling-Basis Risk & Ranking Evolution\")\n",
        "\n",
        "    ticker_rb = st.selectbox(\"Select Ticker\", stock_options, index=0, key=\"rbm_ticker\")\n",
        "    start_rb  = st.date_input(\"Start Date\", datetime(2018, 1, 1), key=\"rbm_start\")\n",
        "    end_rb    = st.date_input(\"End Date\",   datetime(2021, 9, 30), key=\"rbm_end\")\n",
        "    window_rb = st.slider(\"Rolling Window (days)\", 30, 252, 126, key=\"rbm_window\")\n",
        "\n",
        "    all_measures = list(rbm.RISK_FUNCS.keys())\n",
        "    chosen = st.multiselect(\"Which risk measures?\", all_measures, default=[\"Standard Sharpe\"])\n",
        "\n",
        "    if st.button(\"Compute Rolling Risk\", key=\"rbm_run\"):\n",
        "        # if you need a benchmark series for info ratio:\n",
        "        benchmark = yf.download(\"^GSPC\",\n",
        "                               start=start_rb.strftime(\"%Y-%m-%d\"),\n",
        "                               end=end_rb.strftime(\"%Y-%m-%d\"),\n",
        "                               progress=False)\n",
        "\n",
        "        risk_df, rank_df = rbm.compute_rolling_risk(\n",
        "            ticker_rb,\n",
        "            start_rb.strftime(\"%Y-%m-%d\"),\n",
        "            end_rb.strftime(\"%Y-%m-%d\"),\n",
        "            window=window_rb,\n",
        "            measures=chosen,\n",
        "            benchmark=benchmark\n",
        "        )\n",
        "\n",
        "        st.subheader(\"Raw Rolling Risk Measures\")\n",
        "        st.line_chart(risk_df[chosen], use_container_width=True)\n",
        "\n",
        "        st.subheader(\"Rolling-Rankings\")\n",
        "        st.line_chart(rank_df[chosen], use_container_width=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6nwCMkphmqp",
        "outputId": "ad20f313-4087-401a-8698-24312bd9b6d3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "\"\"\"\n",
        "with tabs[x]:\n",
        "    st.header(\"Trading-Strategy Simulations\")\n",
        "    ticker = st.selectbox(\"Select Ticker\", stock_options, index=0, key=\"tsm_ticker\")\n",
        "    start_date = st.date_input(\"Start Date\", datetime(2018, 1, 1), key=\"tsm_start\")\n",
        "    end_date   = st.date_input(\"End Date\",   datetime(2021, 9, 30), key=\"tsm_end\")\n",
        "\n",
        "    if st.button(\"Run Simulations\", key=\"tsm_run\"):\n",
        "        df_results, cum_series = tsm.run_trading_simulations(\n",
        "            ticker,\n",
        "            start_date.strftime(\"%Y-%m-%d\"),\n",
        "            end_date.strftime(\"%Y-%m-%d\")\n",
        "        )\n",
        "\n",
        "        st.subheader(\"Summary Results\")\n",
        "        st.dataframe(df_results)\n",
        "\n",
        "        st.subheader(\"Cumulative Returns Over Time\")\n",
        "        for name, series in cum_series.items():\n",
        "            st.line_chart(series, height=250, use_container_width=True)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "oRKmRES9SK5-",
        "outputId": "a920701d-845c-4bf6-b6ca-8bd86f007376"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nwith tabs[x]:\\n    st.header(\"Trading-Strategy Simulations\")\\n    ticker = st.selectbox(\"Select Ticker\", stock_options, index=0, key=\"tsm_ticker\")\\n    start_date = st.date_input(\"Start Date\", datetime(2018, 1, 1), key=\"tsm_start\")\\n    end_date   = st.date_input(\"End Date\",   datetime(2021, 9, 30), key=\"tsm_end\")\\n\\n    if st.button(\"Run Simulations\", key=\"tsm_run\"):\\n        df_results, cum_series = tsm.run_trading_simulations(\\n            ticker,\\n            start_date.strftime(\"%Y-%m-%d\"),\\n            end_date.strftime(\"%Y-%m-%d\")\\n        )\\n\\n        st.subheader(\"Summary Results\")\\n        st.dataframe(df_results)\\n\\n        st.subheader(\"Cumulative Returns Over Time\")\\n        for name, series in cum_series.items():\\n            st.line_chart(series, height=250, use_container_width=True)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok > /dev/null"
      ],
      "metadata": {
        "id": "Mj_iRrcHh1Iz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"YOUR AUTHTOKEN\")  # authtoken\n",
        "\n",
        "os.system(\"pkill streamlit\")\n",
        "os.system(\"pkill -f ngrok\")\n",
        "\n",
        "time.sleep(3)"
      ],
      "metadata": {
        "id": "ngnwKqHo9H81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "100a4705-ac29-4bfc-acc3-4608582751ba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open an ngrok tunnel on port 8501.\n",
        "public_url = ngrok.connect(8501, \"http\")\n",
        "\n",
        "# Launch the Streamlit app in the background.\n",
        "os.system(\"streamlit run app.py &\")\n",
        "\n",
        "time.sleep(5)\n",
        "print(\"Your Streamlit app is available at:\", public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfOXjJgWhpoM",
        "outputId": "22418397-0e6c-4aa1-a342-6c738c25e7f7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-04-26T19:27:05+0000 lvl=warn msg=\"failed to check for update\" obj=updater err=\"Post \\\"https://update.equinox.io/check\\\": context deadline exceeded\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your Streamlit app is available at: NgrokTunnel: \"https://4e63-35-243-173-244.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}